# Data Sources Overview

This reference explains every CSV emitted by the GDPR enforcement data pipeline and how each file is produced. Follow the phase order to trace provenance.

## Phase 1 – Extraction (`outputs/phase1_extraction/`)
- `main_dataset.csv`: Generated by `python3 scripts/1_parse_ai_responses.py`. Contains 757 rows × 77 columns mapped directly from `raw_data/AI_analysis/AI-responses.txt` (one row per decision with all schema fields). Use as the canonical starting point for validation and repair.
- `data_with_errors.csv`: Also produced by the parser when answers are incomplete. Holds the 11 response bundles that were missing questions 74-77; kept for manual follow-up, never fed into later phases.

## Phase 2 – Validation (`outputs/phase2_validation/`)
- `validated_data.csv`: Output of `python3 scripts/2_validate_dataset.py` without arguments. Lists the subset of Phase 1 rows that pass every schema rule and cross-field constraint.
- `validation_errors.csv`: Detailed error ledger (row id, field, value, rule, severity) emitted by the validator for the rows that failed. Drives rule design in Phase 3.
- `validation_report.txt`: Human-readable summary of the validation run (row counts, error totals, top offending fields).
- `enum_analysis.csv` / `enum_analysis.txt`: Produced by `python3 scripts/2_analyze_enum_values.py` to show frequency of valid vs invalid enum tokens across all columns.

## Phase 3 – Repair (`outputs/phase3_repair/`)
- `repaired_dataset.csv`: Created by `python3 scripts/3_repair_data_errors.py`. Applies six targeted enum repairs to the Phase 1 dataset using the Phase 2 error log.
- `repair_log.txt`: Companion log that lists every applied repair (row id, field, from → to, pattern name).
- `repaired_dataset_validated.csv`: Generated by re-running `python3 scripts/2_validate_dataset.py --input outputs/phase3_repair/repaired_dataset.csv`. Contains the 623 post-repair rows that pass all validation checks.
- `repaired_dataset_validation_errors.csv`: Validation failures that remain after repairs; use this to decide whether to extend pattern coverage or perform manual curation.
- `repaired_dataset_validation_report.txt`: Summary stats for the post-repair validation pass (mirrors the Phase 2 report format).

Keep this document close when sharing datasets or designing new automation so collaborators can confirm which artefacts are authoritative for a given workflow stage.
